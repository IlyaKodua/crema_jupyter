{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import cv2\n",
    "import dlib\n",
    "import imutils\n",
    "from mlxtend.image import extract_face_landmarks\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22326"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv = pd.read_csv(\"processedResults/summaryTable.csv\")\n",
    "labels_csv = pd.read_csv(\"processedResults/tabulatedVotes.csv\")\n",
    "len(labels_csv[\"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>FileName</th>\n",
       "      <th>VoiceVote</th>\n",
       "      <th>VoiceLevel</th>\n",
       "      <th>FaceVote</th>\n",
       "      <th>FaceLevel</th>\n",
       "      <th>MultiModalVote</th>\n",
       "      <th>MultiModalLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1001_IEO_NEU_XX</td>\n",
       "      <td>N</td>\n",
       "      <td>69.1</td>\n",
       "      <td>N</td>\n",
       "      <td>92.22</td>\n",
       "      <td>N</td>\n",
       "      <td>64.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1001_IEO_HAP_LO</td>\n",
       "      <td>N</td>\n",
       "      <td>71.67</td>\n",
       "      <td>H</td>\n",
       "      <td>57</td>\n",
       "      <td>H</td>\n",
       "      <td>57.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1001_IEO_HAP_MD</td>\n",
       "      <td>N</td>\n",
       "      <td>67.71</td>\n",
       "      <td>H</td>\n",
       "      <td>62.62</td>\n",
       "      <td>H</td>\n",
       "      <td>56.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1001_IEO_HAP_HI</td>\n",
       "      <td>H</td>\n",
       "      <td>63.5</td>\n",
       "      <td>H</td>\n",
       "      <td>68.25</td>\n",
       "      <td>H</td>\n",
       "      <td>73.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1001_IEO_SAD_LO</td>\n",
       "      <td>N</td>\n",
       "      <td>73.71</td>\n",
       "      <td>N</td>\n",
       "      <td>73.5</td>\n",
       "      <td>N</td>\n",
       "      <td>74.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         FileName VoiceVote VoiceLevel FaceVote FaceLevel  \\\n",
       "0           1  1001_IEO_NEU_XX         N       69.1        N     92.22   \n",
       "1           2  1001_IEO_HAP_LO         N      71.67        H        57   \n",
       "2           3  1001_IEO_HAP_MD         N      67.71        H     62.62   \n",
       "3           4  1001_IEO_HAP_HI         H       63.5        H     68.25   \n",
       "4           5  1001_IEO_SAD_LO         N      73.71        N      73.5   \n",
       "\n",
       "  MultiModalVote MultiModalLevel  \n",
       "0              N           64.78  \n",
       "1              H           57.38  \n",
       "2              H           56.56  \n",
       "3              H            73.2  \n",
       "4              N            74.8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_csv = labels_csv[:7442]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "      <th>H</th>\n",
       "      <th>N</th>\n",
       "      <th>S</th>\n",
       "      <th>fileName</th>\n",
       "      <th>numResponses</th>\n",
       "      <th>agreement</th>\n",
       "      <th>...</th>\n",
       "      <th>meanSadResp</th>\n",
       "      <th>medianEmoResp</th>\n",
       "      <th>meanEmoRespNorm</th>\n",
       "      <th>meanAngerRespNorm</th>\n",
       "      <th>meanDisgustRespNorm</th>\n",
       "      <th>meanFearRespNorm</th>\n",
       "      <th>meanHappyRespNorm</th>\n",
       "      <th>meanNeutralRespNorm</th>\n",
       "      <th>meanSadRespNorm</th>\n",
       "      <th>medianEmoRespNorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1001_IEO_NEU_XX</td>\n",
       "      <td>11</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>66.171320</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>97.894737</td>\n",
       "      <td>62.998978</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1001_IEO_HAP_LO</td>\n",
       "      <td>9</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>53.816160</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>36.292735</td>\n",
       "      <td>62.577873</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>53.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1001_IEO_HAP_MD</td>\n",
       "      <td>11</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.874713</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.165230</td>\n",
       "      <td>65.708703</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>61.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1001_IEO_HAP_HI</td>\n",
       "      <td>10</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>69.5</td>\n",
       "      <td>52.927309</td>\n",
       "      <td>84.420185</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>56.542708</td>\n",
       "      <td>10.588235</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>66.308140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1001_IEO_SAD_LO</td>\n",
       "      <td>10</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>59.486728</td>\n",
       "      <td>12.941176</td>\n",
       "      <td>94.936709</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>69.123485</td>\n",
       "      <td>3.125</td>\n",
       "      <td>75.182073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  A  D  F  H   N  S         fileName  numResponses  agreement  \\\n",
       "0      100001  0  0  0  1  10  0  1001_IEO_NEU_XX            11   0.909091   \n",
       "1      100002  0  0  0  3   6  0  1001_IEO_HAP_LO             9   0.666667   \n",
       "2      100003  0  0  0  4   7  0  1001_IEO_HAP_MD            11   0.636364   \n",
       "3      100004  2  0  0  6   2  0  1001_IEO_HAP_HI            10   0.600000   \n",
       "4      100005  1  1  0  0   7  1  1001_IEO_SAD_LO            10   0.700000   \n",
       "\n",
       "   ... meanSadResp  medianEmoResp  meanEmoRespNorm  meanAngerRespNorm  \\\n",
       "0  ...        -1.0           87.0        66.171320          -1.000000   \n",
       "1  ...        -1.0           72.0        53.816160          -1.000000   \n",
       "2  ...        -1.0           60.0        61.874713          -1.000000   \n",
       "3  ...        -1.0           69.5        52.927309          84.420185   \n",
       "4  ...         6.0           80.0        59.486728          12.941176   \n",
       "\n",
       "   meanDisgustRespNorm  meanFearRespNorm  meanHappyRespNorm  \\\n",
       "0            -1.000000              -1.0          97.894737   \n",
       "1            -1.000000              -1.0          36.292735   \n",
       "2            -1.000000              -1.0          55.165230   \n",
       "3            -1.000000              -1.0          56.542708   \n",
       "4            94.936709              -1.0          -1.000000   \n",
       "\n",
       "   meanNeutralRespNorm  meanSadRespNorm  medianEmoRespNorm  \n",
       "0            62.998978           -1.000          83.333333  \n",
       "1            62.577873           -1.000          53.846154  \n",
       "2            65.708703           -1.000          61.111111  \n",
       "3            10.588235           -1.000          66.308140  \n",
       "4            69.123485            3.125          75.182073  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = labels_csv[\"A\"]\n",
    "D = labels_csv[\"D\"]\n",
    "F = labels_csv[\"F\"]\n",
    "H = labels_csv[\"H\"]\n",
    "N = labels_csv[\"N\"]\n",
    "S = labels_csv[\"S\"]\n",
    "classes = {\n",
    "\"Anger\" : 0, \n",
    "\"Disgust\" : 1,\n",
    "\"Fear\" : 2,\n",
    "\"Happy\" : 3,\n",
    "\"Neutral\" : 4,\n",
    "\"Sad\" : 5\n",
    "}\n",
    "inv_map = {v: k for k, v in classes.items()}\n",
    "classes_str = [\"Anger\", \"Disgust\",\"Fear\",\"Happy\",\"Neutral\",\"Sad\"]\n",
    "classes_russ = [\"Гнев\", \"Отвращение\",\"Страх\",\"Счастье\",\"Нет эмоций\",\"Грусть\"]\n",
    "hist_data = np.zeros(6)\n",
    "# labels = np.zeros((len(A), 6))\n",
    "labels = np.zeros((len(A), 1), dtype= np.uint)\n",
    "for i in range(len(A)):\n",
    "    labels[i] = int(np.argmax(np.array([A[i], D[i], F[i], H[i], N[i], S[i]], dtype=np.float32)))\n",
    "    hist_data[labels[i]] += 1\n",
    "\n",
    "with open('data_pkl/labels.pkl', 'wb') as f:\n",
    "    pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.bar(classes_russ, height = hist_data,color = \"r\")\n",
    "plt.savefig(\"img_example/hist_classes.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7442"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = data_csv[\"FileName\"]\n",
    "files_wav = \"AudioMP3/\" + files + \".mp3\"\n",
    "files_video = \"VideoFlash/\" + files + \".flv\"\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_video = files_video\n",
    "files_wav = files_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_resize(y, len_y):\n",
    "    if(len(y) >= len_y):\n",
    "        return y[0:len_y]\n",
    "    else:\n",
    "        return np.pad(y, [(0, len_y - len(y))], mode='constant', constant_values=0)\n",
    "\n",
    "def mel_norm(mel):\n",
    "    return 2*np.log(1 + mel) / np.log(1 + np.max(mel)) - 1\n",
    "\n",
    "def mfcc_norm(mfcc):\n",
    "    return 2*(mfcc - np.min(mfcc)) / (np.max(mfcc) - np.min(mfcc)) - 1\n",
    "\n",
    "def get_audio_mfcc(files_wav):\n",
    "    len_y = int(16e3*12) #median len (4608 + 2725632) / 2\n",
    "    data_mfcc = []\n",
    "    data_mel = []\n",
    "    time = []\n",
    "    warnings.filterwarnings('ignore')\n",
    "    for i, file in enumerate(files_wav):\n",
    "\n",
    "        cycl_persent = int((i+1)/len(files_wav)*100)\n",
    "        print(cycl_persent, \" %\")\n",
    "\n",
    "\n",
    "        y, sr = librosa.load(file, sr = None)\n",
    "        time.append(len(y)/16e3)\n",
    "        y = my_resize(y, len_y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,\n",
    "                            fmax=16e3)\n",
    "        data_mfcc.append(mfcc_norm(mfcc.astype(\"float32\")))\n",
    "        data_mel.append(mel_norm(mel.astype(\"float32\")))\n",
    "    return data_mel, data_mfcc, time\n",
    "# data_mel, data_mfcc, time = get_audio_mfcc(files_wav)\n",
    "\n",
    "# with open('data_pkl/data_mel.pkl', 'wb') as f:\n",
    "#     pickle.dump(data_mel, f)\n",
    "\n",
    "\n",
    "# with open('data_pkl/time.pkl', 'wb') as f:\n",
    "#     pickle.dump(time, f)\n",
    "\n",
    "# with open('data_pkl/data_mfcc.pkl', 'wb') as f:\n",
    "#     pickle.dump(data_mfcc, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with open(r\"data_pkl/time.pkl\", \"rb\") as input_file:\n",
    "    time = pickle.load(input_file)\n",
    "time = np.array(time)\n",
    "time[time == np.max(time)] = np.median(time)\n",
    "plt.hist(time, density=True, bins=50)  # density=False would make counts\n",
    "plt.ylabel('Вероятность')\n",
    "plt.xlabel('Время, с')\n",
    "plt.savefig(\"img_example/hist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192000.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16e3*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_trim_bb(image, rect):\n",
    "\t# extract the starting and ending (x, y)-coordinates of the\n",
    "\t# bounding box\n",
    "\tstartX = rect.left()\n",
    "\tstartY = rect.top()\n",
    "\tendX = rect.right()\n",
    "\tendY = rect.bottom()\n",
    "\t# ensure the bounding box coordinates fall within the spatial\n",
    "\t# dimensions of the image\n",
    "\tstartX = max(0, startX)\n",
    "\tstartY = max(0, startY)\n",
    "\tendX = min(endX, image.shape[1])\n",
    "\tendY = min(endY, image.shape[0])\n",
    "\t# compute the width and height of the bounding box\n",
    "\tw = endX - startX\n",
    "\th = endY - startY\n",
    "\t# return our bounding box coordinates\n",
    "\treturn (startX, startY, w, h)\n",
    "\n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "\t# initialize the list of (x, y)-coordinates\n",
    "\tcoords = np.zeros((68, 2), dtype=dtype)\n",
    "\t# loop over the 68 facial landmarks and convert them\n",
    "\t# to a 2-tuple of (x, y)-coordinates\n",
    "\tfor i in range(0, 68):\n",
    "\t\tcoords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "\t# return the list of (x, y)-coordinates\n",
    "\treturn coords\n",
    "\n",
    "def norm_landmarks(landmarks):\n",
    "\teps = 1e-6\n",
    "\tlandmarks = landmarks.astype(\"float32\").T\n",
    "\tlandmarks[0,:] -= np.min(landmarks[0,:])\n",
    "\tlandmarks[1,:] -= np.min(landmarks[1,:])\n",
    "\tlandmarks[0,:] /= np.max(landmarks[0,:]) + eps\n",
    "\tlandmarks[1,:] /= np.max(landmarks[1,:]) + eps\n",
    "\treturn 2*landmarks - 1\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# 3756\n",
    "def get_face_from_vieo(files_video):\n",
    "\n",
    "    arr_point = []\n",
    "    arr_face = []\n",
    "    cnt_png = 0\n",
    "    timer = time.time()\n",
    "    N = len(files_video)\n",
    "    print(\"len \", len(files_video))\n",
    "    for i in range(N):\n",
    "        cycl_persent = int((i+1)/N*100)\n",
    "        print(cycl_persent, \" %\")\n",
    "        print(time.time() - timer, \" s\")\n",
    "        timer = time.time()\n",
    "        cap = cv2.VideoCapture(files_video[i])\n",
    "        im = np.zeros((64,64,3), dtype = np.float32)\n",
    "        cnt = 0\n",
    "        cnt2 = 0\n",
    "        print(i)\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            cnt2 += 1\n",
    "            if ret:\n",
    "                if cnt2 % 5 != 0:\n",
    "                    continue\n",
    "                detector = dlib.get_frontal_face_detector()\n",
    "                image = imutils.resize(frame, width=600)\n",
    "                rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                rects = detector(rgb, 1)\n",
    "                if len(rects) == 0:\n",
    "                    img = np.zeros_like(image)\n",
    "                    img = cv2.resize(img, (64,64), interpolation = cv2.INTER_AREA)\n",
    "                else:\n",
    "                    box = [convert_and_trim_bb(rgb, r) for r in rects][0]\n",
    "                    img = rgb[box[1]:box[1] + box[3], box[0]:box[0] + box[2],:]\n",
    "                    # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    img = cv2.resize(img, (64,64), interpolation = cv2.INTER_AREA)\n",
    "                im += img/255\n",
    "                cnt += 1\n",
    "            else:\n",
    "                break\n",
    "        # plt.figure(1)\n",
    "        # plt.imshow(im/cnt)\n",
    "        # plt.show()\n",
    "        # plt.imsave('img_example/'+ str(cnt_png) + '.png', im/cnt)\n",
    "        # cnt_png += 1\n",
    "        ln_img = im/cnt*255\n",
    "        ln_img = cv2.cvtColor(ln_img.astype(\"uint8\"), cv2.COLOR_BGR2GRAY)\n",
    "        landmarks = extract_face_landmarks(ln_img.astype(\"uint8\"))\n",
    "        if landmarks is None:\n",
    "            landmarks = np.zeros((62,2))\n",
    "        arr_point.append(norm_landmarks(landmarks))\n",
    "\n",
    "        arr_face.append(2*im/cnt - 1)\n",
    "        cap.release()\n",
    "    return arr_face, arr_point\n",
    "\n",
    "# arr_face, arr_point = get_face_from_vieo(files_video)\n",
    "\n",
    "# print(len(arr_face), \" len\")\n",
    "# with open('data_pkl/arr_face.pkl', 'wb') as f:\n",
    "#     pickle.dump(arr_face, f)\n",
    "\n",
    "# with open('data_pkl/arr_point.pkl', 'wb') as f:\n",
    "#     pickle.dump(arr_point, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"data_pkl/data_mfcc_all.pkl\", \"rb\") as input_file:\n",
    "    mfcc = pickle.load(input_file)\n",
    "with open(r\"data_pkl/data_mel_all.pkl\", \"rb\") as input_file:\n",
    "    mel = pickle.load(input_file)\n",
    "with open(r\"data_pkl/arr_point_all.pkl\", \"rb\") as input_file:\n",
    "    points = pickle.load(input_file)\n",
    "with open(r\"data_pkl/arr_face_all.pkl\", \"rb\") as input_file:\n",
    "    face = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7442, 7520)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_copy = np.asarray(mfcc)\n",
    "mfcc = np.zeros((len(mfcc_copy) , len(mfcc[0].reshape(-1))))\n",
    "for i in range(len(mfcc)):\n",
    "    mfcc[i] = mfcc_copy[i].flatten()\n",
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_copy = np.asarray(mel)\n",
    "mel = np.zeros((len(mel_copy) , len(mel[0].reshape(-1))))\n",
    "for i in range(len(mel)):\n",
    "    mel[i] = mel_copy[i].flatten()\n",
    "mel.shape\n",
    "mel[np.isnan(mel)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7442, 136)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# points = np.array(points)\n",
    "for i, p in enumerate(points):\n",
    "    if p.shape == (2,62):\n",
    "        points[i] = np.concatenate((points[i], np.zeros((2,6))), axis=1)\n",
    "\n",
    "\n",
    "points_copy = np.asarray(points)\n",
    "points = np.zeros((len(points_copy) , len(points[0].reshape(-1))))\n",
    "for i in range(len(points)):\n",
    "    points[i] = points_copy[i].flatten()\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_copy = np.asarray(face)\n",
    "face = np.zeros((len(face_copy) , len(face[0].reshape(-1))))\n",
    "for i in range(len(face)):\n",
    "    face[i] = face_copy[i].flatten()\n",
    "face.shape\n",
    "face[np.isnan(face)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = shuffle(labels, random_state=20)\n",
    "mfcc = shuffle(mfcc, random_state=20)\n",
    "mel = shuffle(mel, random_state=20)\n",
    "points = shuffle(points, random_state=20)\n",
    "face = shuffle(face, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_size = 1e10\n",
    "for i in range(6):\n",
    "    min_size = np.min([np.sum(labels == i), min_size])\n",
    "train_class_size = int(min_size*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = []\n",
    "labels_test = []\n",
    "\n",
    "mfcc_train = []\n",
    "mfcc_test = []\n",
    "\n",
    "mel_test = []\n",
    "mel_train= []\n",
    "\n",
    "points_test = []\n",
    "points_train= []\n",
    "\n",
    "face_train = []\n",
    "face_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counter = np.zeros(6)\n",
    "for i in range(len(labels)):\n",
    "    class_counter[labels[i]] += 1\n",
    "    if class_counter[labels[i]] > train_class_size:\n",
    "        labels_test.append(labels[i])\n",
    "        mfcc_test.append(mfcc[i])\n",
    "        mel_test.append(mel[i])\n",
    "        points_test.append(points[i])\n",
    "        face_test.append(face[i])\n",
    "    else:\n",
    "        labels_train.append(labels[i])\n",
    "        mfcc_train.append(mfcc[i])\n",
    "        mel_train.append(mel[i])\n",
    "        points_train.append(points[i])\n",
    "        face_train.append(face[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_train = np.array(mfcc_train)\n",
    "mel_train = np.array(mel_train)\n",
    "points_train = np.array(points_train)\n",
    "face_train = np.array(face_train)\n",
    "labels_train = np.array(labels_train)\n",
    "mfcc_test= np.array(mfcc_test)\n",
    "mel_test = np.array(mel_test)\n",
    "points_test = np.array(points_test)\n",
    "face_test = np.array(face_test)\n",
    "labels_test = np.array(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1776, 7520)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1776, 48128)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feach_train =  np.concatenate((mfcc_train, mel_train, points_train, face_train), axis=1)\n",
    "feach_test =  np.concatenate((mfcc_test, mel_test, points_test, face_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_mfcc =  svm.NuSVC(gamma=\"auto\", random_state= 20, probability=True, class_weight = \"balanced\")\n",
    "\n",
    "\n",
    "svm_mfcc.fit(mfcc_train, labels_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mfcc = svm_mfcc.predict_proba(mfcc_test)\n",
    "y_pred = np.argmax(p_mfcc, axis = 1)\n",
    "\n",
    "acc_mfcc = f1_score(labels_test, y_pred, average='macro')\n",
    "print(\"acc: \", acc_mfcc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_mel = svm.SVC( random_state= 20, probability=True, class_weight = \"balanced\")\n",
    "svm_mel.fit(mel_train, labels_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svm_mel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7863/1449882019.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp_mel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_mel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_mel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0macc_mel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"acc: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'svm_mel' is not defined"
     ]
    }
   ],
   "source": [
    "p_mel = svm_mel.predict_proba(mel_test)\n",
    "y_pred = np.argmax(p_mel, axis = 1)\n",
    "\n",
    "acc_mel = f1_score(labels_test, y_pred, average='macro')\n",
    "print(\"acc: \", acc_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_points = KNeighborsClassifier(n_neighbors=10, algorithm='ball_tree', metric='euclidean')\n",
    "svm_points.fit(points_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_points = svm_points.predict_proba(points_test)\n",
    "y_pred = np.argmax(p_points, axis = 1)\n",
    "\n",
    "acc_points = f1_score(labels_test, y_pred, average='macro')\n",
    "print(\"acc: \", acc_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_face = svm.SVC(random_state= 20, probability=True, class_weight = \"balanced\")\n",
    "svm_face.fit(face_train, labels_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_face = svm_face.predict_proba(face_test)\n",
    "y_pred = np.argmax(p_face, axis = 1)\n",
    "\n",
    "acc_face = f1_score(labels_test, y_pred, average='macro')\n",
    "print(\"acc: \", acc_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_acc = acc_face + acc_mel + acc_mfcc + acc_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_final = (p_mfcc * (acc_mfcc) +  p_mel * (acc_mel) + p_face * (acc_face) + p_points * (acc_points) )/sum_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(pr_final, axis = 1)\n",
    "\n",
    "acc_final = f1_score(labels_test, y_pred, average='macro')\n",
    "print(\"acc: \", acc_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_all =  svm.NuSVC(kernel= \"poly\",  random_state= 20, probability=True, class_weight = \"balanced\")\n",
    "tree_all =  RandomForestClassifier(max_depth=200, n_estimators=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7863/4000040852.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  tree_all.fit(feach_train, labels_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=200)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_all.fit(feach_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liya/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NuSVC(class_weight='balanced', kernel='poly', probability=True, random_state=20)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_all.fit(feach_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_svm= svm_all.predict_proba(feach_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(p_svm, axis = 1)\n",
    "f1_svm =  f1_score(labels_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tree= tree_all.predict_proba(feach_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(p_tree, axis = 1)\n",
    "f1_tree =  f1_score(labels_test, y_pred, average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_all = f1_svm * p_svm + f1_tree *p_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(p_all, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc_feach = f1_score(labels_test, y_pred, average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc all:  0.32052836331183804\n",
      "acc tree:  0.2714225376094008\n",
      "acc svm:  0.31640206357949757\n"
     ]
    }
   ],
   "source": [
    "print(\"acc all: \", acc_feach)\n",
    "print(\"acc tree: \", f1_tree)\n",
    "print(\"acc svm: \", f1_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7863/1289807534.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  tree_all.fit(feach_train, labels_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7863/1289807534.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  tree_all.fit(feach_train, labels_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7863/1289807534.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  tree_all.fit(feach_train, labels_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7863/1289807534.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  tree_all.fit(feach_train, labels_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best n_estimators:  2000\n",
      "best f1:  0.2823341777234647\n"
     ]
    }
   ],
   "source": [
    "f1 = []\n",
    "n_estimators_my = [200, 500, 1000, 2000]\n",
    "for i in range(len(n_estimators_my)):\n",
    "    print(i)\n",
    "    tree_all =  RandomForestClassifier(max_depth=200, n_estimators=n_estimators_my[i])\n",
    "    tree_all.fit(feach_train, labels_train)\n",
    "    f1.append(f1_score(labels_test, tree_all.predict(feach_test) , average='macro')) \n",
    "\n",
    "\n",
    "print(\"best n_estimators: \" , n_estimators_my[np.argmax(f1)])\n",
    "print(\"best f1: \" , np.max(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7863/2188619720.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  tree_all.fit(feach_train, labels_train)\n"
     ]
    }
   ],
   "source": [
    "tree_all =  RandomForestClassifier(max_depth=200, n_estimators= 2000)\n",
    "tree_all.fit(feach_train, labels_train)\n",
    "p_tree= tree_all.predict_proba(feach_test) \n",
    "y_pred = np.argmax(p_tree, axis = 1)\n",
    "f1_tree =  f1_score(labels_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 final:  0.32223304462064106\n"
     ]
    }
   ],
   "source": [
    "p_all = f1_svm * p_svm + f1_tree *p_tree\n",
    "y_pred = np.argmax(p_all, axis = 1)\n",
    "acc_feach = f1_score(labels_test, y_pred, average='macro')\n",
    "print(\"f1 final: \", acc_feach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
